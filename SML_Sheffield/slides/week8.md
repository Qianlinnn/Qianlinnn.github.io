# 逻辑回归

## 概率分类器

* Logistic回归模型是概率分类器的一个示例。

* 令x∈R^p代表特征向量，y代表目标值。
* 对于二元分类问题，我们可以使用y∈{0，1}或y∈{−1，+1}。
* 我们使用伯努利分布对y和x之间的关系进行建模。

## Bernoulli distribution (I)

* 伯努利随机变量Y是只能采用两个可能值的随机变量。
* 例如，与抛硬币实验相关的随机变量Y。
* 将输出“ heads”分配为1（Y = 1），将输出“ tails”分配为0（Y = 0）。

## Bernoulli distribution (II)

![1]()

## How are y and x related in logistic regression?

* 目标特征y遵循伯努利分布

  p(y|x) = Ber(y|µ(x)).

* 注意，概率µ = P（y = 1）明确取决于x。

* 在逻辑回归中，概率µ（x）表示为

  ![2]()

## Decision Boundary 决策边界

* 在训练阶段之后，我们将有w的估计量。
* 对于测试输入向量x ∗，我们计算p（y = 1 | w，x ∗）=σ（w> x ∗）。
* 这将为我们提供0到1之间的值
* 我们定义阈值0.5来决定将x ∗分配给哪个类
* 使用此阈值，我们在输入空间中引入了线性决策边界。

## 拟牛顿法

* 牛顿方向的主要缺点是需要海森矩阵
* 对该二阶导数矩阵的显式计算有时可能很麻烦，容易出错且成本很高。
* 拟牛顿搜索方向提供了一种有吸引力的牛顿方法替代方法
* 它们不需要计算Hessian，但仍然可以达到更快的收敛速度。
* 他们不使用真正的Hessian 而是近似值Bk，该近似值在每个步骤之后都会更新，以考虑到在该步骤中获得的其他知识。

## Limited memory BFGS (L-BFGS)

* 由于存储Hessian占用O（p 2）空间，因此对于非常大的问题，可以使用有限的内存BFGS或L-BFGS。
* 在L-BFGS中，Hk或Hk^( -1) 用对角线加低秩矩阵近似。

* 特别地，乘积Bk (-1)  gk可以通过仅使用m个最新的（sk，zk）对执行sk和zk的内积序列来获得，而忽略较早的信息。

* 因此，存储要求为O（mp）。 通常，m〜20足以满足良好的性能。

## 优化方法应用于逻辑回归

可以使用上述所有方法来找到在对数回归中最小化负对数可能性NLL（w）或对数损失LL（w）的参数向量w。

## 求和形式的算法

* 当算法对数据求和时，我们可以轻松地将计算分布在多个工作人员（例如核心）上。
* 我们只是将数据集划分为与工作人员一样多的部分，为每个工作人员分配其数据份额以对等式求和，最后汇总结果。
* 我们之前看到的优化算法中的梯度和Hessian都具有求和形式。
* 请注意，求和形式不会更改基础算法：它不是近似值，而是精确的实现。

## Stochastic gradient descent (I)

* 在机器学习的传统上，使用整个数据集D = {xn，yn} N n = 1来计算梯度gk和Hessian Hk。
* 但是，有一些设置只能使用部分数据。

* 在线学习：实例（xn，yn）一次出现一个。
* 大型数据集：计算gk和Hk的确切值会很昂贵，即使不是不可能。

* 在随机梯度下降（SGD）中，使用可用实例的子集计算梯度gk。
* 随机一词是指gk的值取决于为计算选择的实例子集的事实

* 在随机设置中，如果使用以下方法计算梯度，则可以找到更好的估计

  ![3]()

* 此设置称为“小批量梯度下降”
* 对于逻辑回归，g_(k,i)将是为− log p（yi | w，xi）计算的梯度。

## Step size in SGD

* 在SGD中，选择η的值尤为重要，因为没有简单的方法来计算它。
* 通常，η的值将取决于迭代k，ηk。

* 它应遵循Robbins-Monro条件

  ![4]()

## 什么是正则化

* 它是指用于防止预测模型过度拟合的技术。

* 它包括在目标函数中添加一个术语（正则化项），以鼓励采用更简单的解决方案。

* 通过正则化，逻辑回归的目标函数将是

  f(w) = NLL(w) + λR(w)

* 其中R（w）是正则项，λ是正则参数。

* 在f（w）的表达式中，我们可以使用LL（w）代替NLL（w）。

* 如果λ= 0，则得到f（w）= NLL（w）。

## Categorical distribution

* 想象一个随机实验，其中输出只能取K个输出之一。
* 可以使用尺寸为K的向量y编码实验的结果，其中只有一项为1，其余为零。

* 实验的K个输出中的每个输出的概率之和为1
* 我们说向量y遵循分类分布

## Multinomial logistic regression

* 分类分布是多项式分布的一种特殊情况。
* 分类分布可用于多类逻辑回归。
* 多类归类问题中的每个实例都是由（x，y）构成的。
* 在多项式逻辑回归中，每个概率µk表示为

![5]()