{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [COM4513-6513]  Introduction to Python for NLP\n",
    "\n",
    "## Instructor: Nikos Aletras\n",
    "\n",
    "The goal of this session (**not assessed**) is to introduce you to [Python 3](https://www.python.org/), Jupyter notebooks and main \"[data science](https://en.wikipedia.org/wiki/Data_science)\" packages that we will\n",
    "use throughout the course. Specifically, you will be presented to NumPy, SciPy, Pandas and Matplotlib libraries which are the backbone for data manipulation and visualisation, and scientific computing in Python. You will also be presented with essential/basic approaches to text pre-processing.\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "- Setup, configure and run Python Jupyter notebooks.\n",
    "- understand Python basic syntax and know where to find further help (e.g. inline help in notebooks).\n",
    "- remember basic text processing tricks\n",
    "- use the basic Numpy, SciPy, Pandas and Matplotlib functionalities.\n",
    "- have a good overview of popular packages useful for scientific computing.\n",
    "\n",
    "\n",
    "\n",
    "## Practicalities\n",
    "\n",
    "It is strongly recommended to use Ubuntu Linux for the labs ([how to login to Ubuntu](https://www.sheffield.ac.uk/cics/desktop/bootingltsp)). On Ubuntu, use `/apps/anaconda/bin/python` to run python from the [Anaconda](http://docs.anaconda.com/anaconda/) distribution. You should also make sure that when using your own machine and operating system (e.g. MacOS, Linux, Windows) any Python package versions should be identical to the ones we use on the University PCs (check the Anaconda version) to avoid any issues in executing your code by the markers (that could result into losing marks). You could also work on Windows machines by using python from the Anaconda prompt but it is not recommended. \n",
    "\n",
    "In general, for developing in Python, you could use standard IDEs like [PyCharm](https://www.jetbrains.com/pycharm/). For all the assignments we will be using [IPython](https://ipython.org/) and [Jupyter](https://jupyter.org/) notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Natural Language Processing/Machine Learning/Data Science\n",
    "\n",
    "### Pros\n",
    "\n",
    "- Open source - free to install\n",
    "- Large scientific community (all new cool machine learning libraries are mostly introduced in Python)\n",
    "- Easy to learn\n",
    "- Widely used in industry for building data science products\n",
    "- Allows interfacing with C/C++ via the Cython library (<http://cython.org/>)\n",
    "- Easy GPU computing via CUDA + ML libraries\n",
    "- Parallelisation with OpenMP\n",
    "\n",
    "### Cons\n",
    "\n",
    "- Interpreted (not-compiled) language.\n",
    "- Python code might be slower compared to C/C++\n",
    "- Not ideal for multithread applications; the interpreter prevents from executing one Python bytecode at a time, Global Interpreter Lock (GIL) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Scientific Python Libraries that we will use in the course\n",
    "\n",
    "\n",
    "### NumPy    \n",
    "\n",
    "Numerical Python (<http://www.numpy.org/> ) is the foundational package for scientific computing in Python. Most of the other scientific computing libraries are built on top of NumPy. \n",
    "\n",
    "- Provides a fast and efficient multidimensional array object *ndarray* \n",
    "- Computations and operations between arrays\n",
    "- Serialisation of array objects to disk\n",
    "- Linear algebra operations and other mathematical operations\n",
    "- Integrating C, C++ and Fortran code to Python (e.g. BLAS and Lapack libraries)\n",
    "\n",
    "### SciPy\n",
    "\n",
    "SciPy (<https://www.scipy.org/> ) is scientific computing and technical computing library. SciPy contains modules for optimization, linear algebra, integration, interpolation.\n",
    "\n",
    "### Pandas\n",
    "\n",
    "Pandas (<https://pandas.pydata.org/>) is a library that provides richer data structures compared to NumPy called *DataFrames*. DataFrames are similar to the ones used in R (*data.frame*) and allow sophisticated indexing functionallity for reshaping, slicing and dicing, aggregating data sets.  \n",
    "\n",
    "\n",
    "### Matplotlib\n",
    "\n",
    "Matplotlib (<https://matplotlib.org/>) is the basic plotting library in Python.\n",
    "\n",
    "### Seaborn\n",
    "\n",
    "Seaborn (<https://seaborn.pydata.org/>) is a visualization library based on matplotlib. It makes it easier for drawing graphs by providing a high-level interface to matplotlib. It can also directly plot Pandas dataframes.\n",
    "\n",
    "\n",
    "### IPython\n",
    "\n",
    "IPython (Interactive Python <https://ipython.org/>) provides a platform for interactive computing (shells) that offers introspection, rich media, shell syntax, tab completion and history.\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Jupyter (https://jupyter.org/) is a web-based application that allows to crerate documents (i.e. notebooks) that contain executable code, rich media and markdown inter alia. Jupyter interacts with Python via an IPython kernel.\n",
    "\n",
    "\n",
    "### Anaconda\n",
    "\n",
    "Anaconda (<https://www.anaconda.com/distribution/>) is a free and open-source Python (and R) distribution that comes bundled with all the essential (and many more) packages for data sciene and machine learning. Anaconda also offers management of packages, dependencies and environments.\n",
    "\n",
    "\n",
    "### Other popular NLP and ML Libraries \n",
    "\n",
    "- SpaCy (<https://spacy.io/>) is an open-source library for Natural Language Processing.\n",
    "\n",
    "- NLTK (<https://www.nltk.org/>) is a package that provides text processing libraries for classification, tokenization, stemming, tagging, parsing etc.. \n",
    "\n",
    "- Scikit-learn (<https://scikit-learn.org>) is an open-source machine learning library. \n",
    "\n",
    "- Tensorflow (<https://www.tensorflow.org/>) and PyTorch (<https://pytorch.org/>) are popular open-source libraries for implementing and training neural network architectures.\n",
    "\n",
    "- Keras (<https://keras.io/>) is a library that provides high level abstractions for implementing neural network architectures (built on top of Tensorflow)\n",
    "\n",
    "**Note that you are not allowed (unless it is explicitly specified) to use any of these six libraries in the assignments**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "Thanks to Anaconda, all above packages come in one bundle so if you use your own machine, you just need to install Anaconda for Python 3 following the instructions here: <http://docs.anaconda.com/anaconda/install/> (**already installed on University's machines**)\n",
    " \n",
    "Note that Anaconda supports Windows, MacOS and Linux. Choose your OS and follow the instructions!\n",
    "\n",
    " \n",
    "You can load this notebook by running: \n",
    "\n",
    "- `$ /apps/anaconda/bin/jupyter notebook a0_python_intro.ipynb` on uni machines\n",
    "\n",
    "or\n",
    "\n",
    "- `$ jupyter notebook a0_python_intro.ipynb` on your own machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics \n",
    "\n",
    "You can skip this section if you are already familiar with basic Python functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?len \n",
    "\n",
    "#get help for a property or a method on Jupyter/Ipython: \n",
    "# ? followed by the method or property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.<TAB> \n",
    "\n",
    "#do not run this cell, if you hit tab after typing `str.` you will get a \n",
    "#list with all available properties and methods of an object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python 3 supports dynamic typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 5.0 \n",
    "y = True\n",
    "y = 'data'\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace Formatting\n",
    "\n",
    "Python uses identation to delimit blocks of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identation could be either 5 spaces or a tab, however it should be consistent throughout the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i+10)\n",
    "        print(i-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whitespace is ignored inside paretheses and brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a backslash to indicate that a statement continues to next line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + \\\n",
    "1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules\n",
    "\n",
    "Not all available functionality is loaded by default, however we can load build-in or third-party modules (packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.gauss(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.normal([0, 0], [1,10], size=[5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Functions take zero or more inputs and return an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_squared(x):\n",
    "    return x**2 #x power of 2\n",
    "\n",
    "# using positional arguments\n",
    "def x_squared_new(x=3):\n",
    "    return x**2 #x power of 2\n",
    "\n",
    "a = x_squared(2)\n",
    "b = x_squared_new()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"natural\"\n",
    "b = 'language'\n",
    "c = a+' '+b # concatenate strings\n",
    "c, len(c) # string length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1,2,3,4,5] # list with 3 integers\n",
    "l2 = [1,'a'] # list with one int and one char\n",
    "l2[1] = 2 # update the value of the second element of the list\n",
    "l3 = [l1, l2, []] #list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use : to slice the list\n",
    "l1[:] # [1,2,3,4,5] - copy of l1\n",
    "l1[1:4] # [2,3,4]\n",
    "l1[:2] # [1,2]\n",
    "l1[2:] # [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1[-1] # choose the last element\n",
    "l1[-3:] # last three elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check list membership\n",
    "1 in [1,2] #True\n",
    "1 in [2,3] #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list concatenation\n",
    "x = [1,2,3]\n",
    "y = [4]\n",
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append(5) # append an item at the end of the list\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x) # length of the list, that's 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x+1 for x in range(50,100,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "\n",
    "Similar to list but no element modifications are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2,3) +(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "Data structures that associate keys to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {} #empty dictionary\n",
    "d = dict() #empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Joe'] = 10\n",
    "d['Mary'] = 30\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Mary' in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d) # size of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d['Mary'] # delete key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "s.add(1)\n",
    "s.add(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = set([4,5,5,5,4,4,4,4,2])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s & v # intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s | v # union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1>2:\n",
    "    print(\"Yes!\")\n",
    "else:\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "if i<0:\n",
    "    i=10\n",
    "elif i>0 and i<=5:\n",
    "    i=20\n",
    "else:\n",
    "    i=30\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "while x < 2:\n",
    "    print(x, \"is less than 2\")\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print('Sure!')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.random() produces numbers uniformly between 0 and 1\n",
    "v = [random.random() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123) # set the random seed to get reproducible results! \n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "random.random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.uniform(-1, 1) # set the boundaries to sample uniformly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object-Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLmodel:\n",
    "    \n",
    "    # member functions for a linear regression model\n",
    "    # y = input * w (input: vector, w: weights)\n",
    "    \n",
    "    def __init__(self, w=None, params_size=3):\n",
    "        # constructor to initialise a model\n",
    "        # self. w is the weight vector (parameters)\n",
    "        # if w is not set, we initialise it randomly\n",
    "        # note that self.w  and w are different! \n",
    "        if w == None:\n",
    "            self.w = [random.uniform(-0.1,0.1) for _ in range(params_size)]\n",
    "        else:\n",
    "            self.w = w \n",
    "        \n",
    "    def predict(self,X):\n",
    "        return sum([X[i]*self.w[i] for i in range(len(self.w))])\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        #not implemented\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2., 5., 0]\n",
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLmodel(params_size=5)\n",
    "x = [2., 5., 0, 18, 9]\n",
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw text\n",
    "d = \"\"\"\n",
    "    the cat sat on the mat\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tok = d.split() # simple whitespace tokenisation\n",
    "d_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(d_tok) # obtain a vocabulary using a set\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a vocab_id to word dictionary\n",
    "id2word = enumerate(vocab)\n",
    "id2word = dict(id2word)\n",
    "id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you generate a word2id dictionary? E.g. {'on':0, 'the':2 ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:29:00.110304Z",
     "start_time": "2020-01-22T11:29:00.100274Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "numRE = re.compile('[0-9]+')\n",
    "\n",
    "numRE.findall('45 09 dfs 56352 tta& 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:31:19.364643Z",
     "start_time": "2020-01-22T11:31:19.359883Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "a = Counter(['a', 'foo', 'foo', 'a', 'foo'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced list handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:34:58.366635Z",
     "start_time": "2020-01-22T11:34:58.362809Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a new list by aligning elements from two lists\n",
    "a = list(zip([1,2,3,4], [2,3,4,5,6])) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:37:28.566726Z",
     "start_time": "2020-01-22T11:37:28.561331Z"
    }
   },
   "outputs": [],
   "source": [
    "list(zip([1,2,3,4], [2,3,4,5,6], [3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:35:18.964277Z",
     "start_time": "2020-01-22T11:35:18.959888Z"
    }
   },
   "outputs": [],
   "source": [
    "list(zip(*a)) # unzip a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T11:34:36.601204Z",
     "start_time": "2020-01-22T11:34:36.597065Z"
    }
   },
   "outputs": [],
   "source": [
    "# enumerate elements of a list\n",
    "list(enumerate(['a','b','c'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Arrays\n",
    "\n",
    "NumPy array are similar to  Python lists, except  that  every  element  of  an  array  must  be  of  the  same  type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3], np.float32)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to range(3) or np.arange(0,3,1)\n",
    "# last argument is the step\n",
    "np.arange(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]=80\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multidimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1,2,3,4,5],[6,7,8,9,10]])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing across dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1:,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *shape* property returns a tuple with the size of each dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dtype* property returns the data type of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the array with a different data type\n",
    "c = b.astype(np.float) \n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reshape((5,2)) # change shape, keep the same number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.transpose() # transpose an array -- same as c.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.flatten() # flatten an array, resulting to 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([10,20])\n",
    "c = np.array([100, 200])\n",
    "# concatenate two or more arrays\n",
    "np.concatenate((a, b, c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((a,b)) # stack vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((b,a)) # stack horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXCERCISE** Form the 2-D array (without typing it in explicitly):\n",
    "\n",
    "```python\n",
    "[[1,  6, 11],\n",
    " [2,  7, 12],\n",
    " [3,  8, 13],\n",
    " [4,  9, 14],\n",
    " [5, 10, 15]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dot(np.array([1,2,3,4,5])) # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[0,1],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b #elementwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Array Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[0,1],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([100,-1,20,5.6])\n",
    "c.sort() # sort an array (inplace)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison operators, value testing, item selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,9])\n",
    "b = np.array([4,2,8,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a >= b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nonzero(a>=b) # indices of the nonzero elements e.g. True\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a>=b) # check where a>= b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[idx] #select elements in a where a >= b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.nonzero() # non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(a) # check for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([3,1,2]) # array of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[idx] # subset of a containing the elements in idx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector and matrix mathematics - Basic Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3],[2,3,4],[5,6,7]], np.float)\n",
    "b = np.array([0, 1, 1], np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a,b) # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a.T,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(a, b) # inner product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(a,b) # outer product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cross(a, b) #cross product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(a) # determinant of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(a) # eigenvalues and eigenvectors\n",
    "vals, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linalg.inv(a) # invert a matrix\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vh = np.linalg.svd(a) # Singular Value Decomposition\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.uniform(-1,1, size=5)\n",
    "x2 = np.random.uniform(-1,1, size=5)\n",
    "\n",
    "#  t-test to test whether the mean of two samples are statistical significant.\n",
    "stats.ttest_ind(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrices\n",
    "\n",
    "Sometimes our data might be so large that cannot fit memory but contain many zeros that we do not need to store. In that case SciPy provides memory efficient sparse matrix data structures. \n",
    "\n",
    "\n",
    "\n",
    "        - csc_matrix: Compressed Sparse Column format\n",
    "\n",
    "        - csr_matrix: Compressed Sparse Row format\n",
    "\n",
    "        - bsr_matrix: Block Sparse Row format\n",
    "\n",
    "        - lil_matrix: List of Lists format\n",
    "\n",
    "        - dok_matrix: Dictionary of Keys format\n",
    "\n",
    "        - coo_matrix: COOrdinate format (aka IJV, triplet format)\n",
    "\n",
    "        - dia_matrix: DIAgonal format\n",
    "\n",
    "See <https://docs.scipy.org/doc/scipy/reference/sparse.html> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]]) \n",
    "# 5 non-zero elements\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1, 0, -1])\n",
    "A.dot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Series* is a one-dimensional *ndarray* with axis labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,np.nan,6,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series can contain any data type casted to an object\n",
    "s = pd.Series([10,True,5,'test',6,8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*DataFrame* is a Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-a8049799c451>\", line 1, in <module>\n",
      "    df = pd.DataFrame(np.random.randn(6,4), index=None, columns=list('ABCD'))\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pytest.py\", line 6, in <module>\n",
      "    from _pytest.assertion import register_assert_rewrite\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\__init__.py\", line 6, in <module>\n",
      "    from _pytest.assertion import rewrite\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\rewrite.py\", line 20, in <module>\n",
      "    from _pytest.assertion import util\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\util.py\", line 5, in <module>\n",
      "    import _pytest._code\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 2, in <module>\n",
      "    from .code import Code  # noqa\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\_code\\code.py\", line 11, in <module>\n",
      "    import pluggy\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pluggy\\__init__.py\", line 16, in <module>\n",
      "    from .manager import PluginManager, PluginValidationError\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pluggy\\manager.py\", line 6, in <module>\n",
      "    import importlib_metadata\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 466, in <module>\n",
      "    __version__ = version(__name__)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 433, in version\n",
      "    return distribution(package).version\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 406, in distribution\n",
      "    return Distribution.from_name(package)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 176, in from_name\n",
      "    dist = next(dists, None)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 362, in <genexpr>\n",
      "    for path in map(cls._switch_path, paths)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 377, in _search_path\n",
      "    if not root.is_dir():\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\pathlib.py\", line 1351, in is_dir\n",
      "    return S_ISDIR(self.stat().st_mode)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\pathlib.py\", line 1161, in stat\n",
      "    return self._accessor.stat(self)\n",
      "OSError: [WinError 123] 文件名、目录名或卷标语法不正确。: 'C:\\\\Spark\\\\spark-3.0.0-preview2-bin-hadoop2.7\\\\python\\\\lib\\\\py4j-<version>-src.zip:%PYTHONPATH%'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=None, columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an index\n",
    "df = pd.DataFrame(np.random.randn(6,4), \n",
    "                  index=pd.date_range('20180101', periods=6), \n",
    "                  columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'] # selecting a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3] # slicing rows by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['20180101':'20180102'] # slicing with a labelled index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20180101'] # selecting by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['A','D']] # selecting multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20180102':'20180105',['C','A']] # row and column slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20180102','A'] # access to scalar values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3] # selecting rows using numeric indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows and columns using numeric indices\n",
    "df.iloc[2:4,0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,0] # getting a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['A'] > 0] # boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0,1] = 0 # setting one value\n",
    "\n",
    "# setting the values of an entire column using a numpy array\n",
    "df.loc[:,'C'] = np.ones(len(df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df > -0.5]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows that have missing data\n",
    "df1.dropna(how='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(value=0) # filling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # Performing a descriptive statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a descriptive statistic on the axis 1\n",
    "df.mean(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.cumsum) # Applying functions to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D'].apply(np.exp) # Applying a function to a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values # get DataFrame values as a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "- Splitting the data into groups based on some criteria\n",
    "- Applying a function to each group independently\n",
    "- Combining the results into a data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['red', 'blue', 'blue', 'red',\n",
    "                          'red', 'red', 'blue', 'blue'],\n",
    "                   'B' : ['red', 'blue', 'green', 'green',\n",
    "                          'blue', 'blue', 'red', 'green'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by A then apply sum (think it as a SQL operation)\n",
    "df.groupby('A').sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['A','B']).sum() # hierachical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A'], columns=['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-964042c9a258>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# write to CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('foo.csv') # write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-6b19e0323aba>\", line 1, in <module>\n",
      "    df = pd.read_csv('foo.csv')\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'foo.csv' does not exist: b'foo.csv'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pytest.py\", line 6, in <module>\n",
      "    from _pytest.assertion import register_assert_rewrite\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\__init__.py\", line 6, in <module>\n",
      "    from _pytest.assertion import rewrite\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\rewrite.py\", line 20, in <module>\n",
      "    from _pytest.assertion import util\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\util.py\", line 5, in <module>\n",
      "    import _pytest._code\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 2, in <module>\n",
      "    from .code import Code  # noqa\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\_pytest\\_code\\code.py\", line 11, in <module>\n",
      "    import pluggy\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pluggy\\__init__.py\", line 16, in <module>\n",
      "    from .manager import PluginManager, PluginValidationError\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\pluggy\\manager.py\", line 6, in <module>\n",
      "    import importlib_metadata\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 466, in <module>\n",
      "    __version__ = version(__name__)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 433, in version\n",
      "    return distribution(package).version\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 406, in distribution\n",
      "    return Distribution.from_name(package)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 176, in from_name\n",
      "    dist = next(dists, None)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 362, in <genexpr>\n",
      "    for path in map(cls._switch_path, paths)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 377, in _search_path\n",
      "    if not root.is_dir():\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\pathlib.py\", line 1351, in is_dir\n",
      "    return S_ISDIR(self.stat().st_mode)\n",
      "  File \"C:\\Users\\90512\\Anaconda3\\lib\\pathlib.py\", line 1161, in stat\n",
      "    return self._accessor.stat(self)\n",
      "OSError: [WinError 123] 文件名、目录名或卷标语法不正确。: 'C:\\\\Spark\\\\spark-3.0.0-preview2-bin-hadoop2.7\\\\python\\\\lib\\\\py4j-<version>-src.zip:%PYTHONPATH%'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'foo.csv' does not exist: b'foo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('foo.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('foo.h5','df')\n",
    "pd.read_hdf('foo.h5','df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allow plotting inline \n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [4.2, 3.8, 3.7, 3.6, 3.55]\n",
    "epochs = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,loss,color='g',\n",
    "         linestyle='dashdot', \n",
    "         label='validation loss');\n",
    "\n",
    "plt.title(\"loss monitoring\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise:** Plot a figure containing two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "In this session, you saw: \n",
    "\n",
    "- How to setup, configure and run Python Jupyter notebooks.\n",
    "- How Python differs from other languages; its basic syntax and know where to find further help (e.g. inline help in notebooks).\n",
    "- Remember basic text processing tricks.\n",
    "- Use of basic Numpy, SciPy, Pandas and Matplotlib functionalities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Practice:**\n",
    "\n",
    "- Go through this [Python tutorial](http://cs231n.github.io/python-numpy-tutorial/) and this [one](http://scipy-lectures.org/index.html) (\"1. Getting started with Python for science\" section) on NumPy, SciPy and matplotlib libriaries.\n",
    "\n",
    "**Extras:**\n",
    "\n",
    "- [Jupyter tutorial](https://www.tutorialspoint.com/jupyter/index.htm) \n",
    "- [Introduction to Unix/Linux](http://www.doc.ic.ac.uk/~wjk/UnixIntro/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
